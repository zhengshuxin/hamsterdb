I Am Legend:

Items are sorted by priority (highest on top).
o a pending  TODO item (for the current release)
. a pending  TODO item (for future releases)
x a finished TODO item

-----------------------------------------------------------------------------
This Branch Is About Integrating The hamsterdb2 Functionality!!!!!
-----------------------------------------------------------------------------
The big headline is:
As a user i want to run many Transactions in parallel with high performance.
I'm using multiple threads b/c my CPU has multiple cores, and expect hamsterdb
to scale with the number of cores.
==============================================================================

x win32: get rid of boost_thread

x boost: configure script should make sure that only boost v 1.46 (or newer)
    is accepted
    -> also test with older versions, but 1.33 definitely does not work
    issue #17: https://github.com/cruppstahl/hamsterdb/issues/17

x metrics: add extkey_cache:hits, :misses

x AES encryption
    x create a test program which encrypts/decrypts data (cbc)
        http://saju.net.in/code/misc/openssl_aes.c.txt
    x ./configure: enable aes by default if -lcrypto is available
    x ./configure: add new option "--disable-encryption"
    x move prototype to .cc file
    x create header file documentation; HAM_PARAM_ENCRYPTION_KEY is a
        16byte array with the key
    x ham_env_create: new option HAM_PARAM_ENCRYPTION_KEY enables encryption
        x do not allow if in-memory 
            x unittest
        x disable mmap if encryption is enabled
            x unittest
    x ham_env_open: new option HAM_PARAM_ENCRYPTION_KEY
        x add unittests for create/open, test good and bad keys
        x disable mmap if encryption is enabled
            x unittest
    x disable direct I/O
    x encrypt/decrypt pages
        x cbc-encrypted with page-id as salt
        x need tests w/ reopen, inserts (growing size, 1 - 512 bytes)
    x encrypt/decrypt the log (everything is already padded)
        x do not use salt
        x need tests w/ recovery
        x also test in recovery.pl
    x add to monster tests
    x extend the Windows build

x clean up Database class
    x split into multiple files
    x remove the TODOs
    x refactor, reformat if necessary
    x db_local.cc has many static functions; remove them

x clean up Cursors
    x different definitions of Page::uncouple_cursor,
        BtreeIndex::uncouple_cursor, btree_uncouple_cursors 
        x reduce to one method
        x instead of calling BtreeIndex::uncouple_cursor in PageManager
            (and others), the function could be moved "up" in the call tree
            into the relevant Btree modules
        x same for BtreeIndex::free_page_extkeys
    x clean up Cursor interface
    x Page::add_cursor, Page::remove_cursor:
        x move to BtreeCursor
        x try to merge with couple(), uncouple(); the following functions
            should exist:
            x set_to_nil()
            x get_state() -> nil | coupled | uncoupled
            x uncouple_from_page()
            x couple_to_page()
            x get_coupled_key(&page, &slot, &dupe_id)
            x get_uncoupled_key()

x clean up BtreeCursor - there still are many TODOs

x Environment::get_incremented_lsn should return void

x Rewrite Cursor::is_nil: fix TODOs, do not allow what==0

x Review Cursor documentation in cursor.h, btree_cursor.h, txn_cursor.h

x Refactor TxnCursor - similar to BtreeCuror
    x in destructor: assert that cursor is nil (do the same in ~BtreeCursor)

x clean up btree.h
    x clean up src/btree_check.cc
    x clean up src/btree_erase.cc
    x clean up src/btree_find.cc
    x clean up src/btree_insert.cc
    x clean up btree.h, remove TODOs
        x descriptor: consolidate setters into a single function 
    x clean up src/btree_node.h
    x clean up src/btree_key.h
    x clean up src/btree_key.cc
    x clean up src/btree_stats.h
    x clean up src/btree_stats.cc
    x clean up src/btree_enum.cc
        x use C++ object instead of generic callback function; users can
            derive from this object
        x move enumerate API to separate header file
    x review usage of Database::get_btree_index - should be protected?

x metrics: memory allocations currently ignore operator new/delete

x refactoring of page.h, page.cc

x reduce the file size if freelist adds page at end of file
    x bool Freelist::is_free(ham_u64_t address, ham_size_t size);
        x tests
    x loop through each page from end to beginning; if page is free: cut off
        the file
        x then truncate the file ("reclaim space")
    x only do this in ham_env_close
    x attention: if a file is truncated then recovery can re-create pages
        that are "outside" of the file boundaries! therefore only
        do this if the log is empty!
    x can be disabled with an (undocumented) flag (HAM_DISABLE_RECLAIM)
    x tests, esp. with reopen, is_free(), freelist allocs at end of file
    x no need to have code checking READ_ONLY - this can never happen
    x check the TODOs - there is at least one that needs fixing
    x verify correctness regarding logging/recovery - the modified freelist
        pages have to be logged before they're flushed (or just flush
        them directly after the modification?)
        x add them to the changeset
        x and flush the changeset when done
        x or flush immediately to disk if logging is disabled
    x split is_free_page to reclaim_page, is_page_free
    x do general refactoring of freelist.h, freelist.cc - remove macros etc
    x rename allocated_bits to free_bits
    x add to changelog

x if a btree page is deleted in btree_erase then the page is not moved to the
    freelist - correct? if yes, fix it
    -> no, everything's good

x page_size and pagesize are used inconsistently; use only one!

x introduce PageManager::close(), split PageManager-destructor,
    otherwise we can't catch the return values

x clean up Environment class
    x move the EnvironmentHeader into a separate module, encapsulating access
        -> class EnvironmentHeader
        -> struct PBtreeDescriptor -> PDatabaseHeader
        x header page access
        x encapsulate configuration access
        x a proxy for retrieving and/or caching the configuration values
    x merge changeset->add and env->set_dirty into a single call
        x Environment::mark_header_page_dirty(Page *, bool) -> void
    x remove the TODOs
    x make sure encryption is not allowed w/ remote a environment
        (or document that it's ignored - same about set_log_dir)
    x make EnvironmentHeader::get_max_databases() private
    x split into multiple files

x get rid of internal_fwd_decl.h

x is the recovery working if there's a crash while the journal is applied?
    -> no, it seems not, because it's disabled. There's actually no reason
        to disable the log, only the journal should be disabled!
    x disable journal while recovery is proceeding
    x run recovery tests

x journal.cc: use ByteArray during recovery/iterating

x log.cc: use ByteArray during recovery/iterating

x rename btree.h/.cc to btree_index.h/.cc

x release-v2.sh
    x test build with disabled AES, add this to the release process
        x check with "ldd", there must not be a dependency to libcrypto!
    x test build with disabled remote, add this to the release process
        x check with "ldd", there must not be a dependency to libuv!
    x test build with disabled tcmalloc, add this to the release process
        x fix issue #26
        x check with "ldd", there must not be a dependency to libtcmalloc_minimal!
    x move "diff" to the end, just warn if the files are different
    x tools-tests are failing
    x improve release process automization; the result of release-v2.sh
        are the following files:
        x tar-ball
        x the README
        x the documentation
        x the Changelog
        x the release notes (a template)

x disable reclaim space on Win32 if mmap is used

x src/config.h: always assume little endian, if nothing else is specified.
    x config.h sets WORDS_BIGENDIAN (for MacOS)
    x win32: remove HAM_LITTLE_ENDIAN from solution files
    x change in README

x issue #25: fix tcmalloc build on MacOS

x add client/server testing to monster testsuite
    x also to performance tests

x improve client/server performance
    currently client/server is 10 times slower than standalone; can we improve
    this, i.e. by using keepalive/open connections?
    x configure.in: remove --diable-server, always use --diable-remote
    x remove mongoose
    x check for libuv in configure.in
    x rewrite server side with libuv
        x server1 should compile and run
        x read_cb must use one ByteArray *per client*
        x accept() must allocate client structure
        x close_cb must release client structure
        x use uv_async_send for ham_srv_add_env
        x then continue with dispatch()
    x in on_read_data(): need a way to get the ham_srv_t structure AND
        the ByteArray buffer
    x handles:
        ham_srv_t stores these tables:
        - handles for environments
        - handles for databases
        - handles for transactions
        - handles for cursors
        - all of them are std::vector< Handle<X> >
            - Handle stores handle, X * (and later maybe even timestamps)
        - handle & 0xffff0000 verweisen auf index i.d. tabelle
        - handle & 0x00001111 ist ein counter
    x handle_connect: needs to send env-path and return env-handle
        x implement in server
        x implement in client
            os_posix.cc: socket-funktionen implementieren
            x server
            x client
        x implement disconnect as well
    x implement all other requests
    x Remote/getEnvParamsTest is still failing
    x remove debug output
    x run valgrind tests
    x remove references to access.log, error.log from the configuration file
        x also in hamzilla
    x reduce memory allocation when packing/unpacking requests
    x run server1/client1 with 10000 keys, then run client1 with a
        local database and compare the performance -> not much better
        than before
    x revert changes in client1, server1
    x run a test with hamzilla
    x port to win32
    x currently it's not allowed to have multiple clients opening the same
        database
        x in handle_db_open: return the open handle if it already is open
    x combining multiple transactions fails in a remote setup:
        ./test --enable-remote --use-transactions=5 --num-threads=5 ../../testfiles/1/01.tst
      ASSERT FAILED in file env.cc, line 53:
        "!"not yet implemented""
        problem: unlike the LocalEnvironment, transactions are not "flushed"
            but simply removed from the linked list, and this is not yet
            implemented.
        Either "flush" them or fix the linked list implementation.
    x unittest/valgrind.txt -> check memory leaks
    x unittest/valgrind.txt -> has warnings
        x CursorFindRequest: sends Record structure, but boolean flag 
            should be enough
        x same for CursorMoveRequest
    x test darwin/MacOS compilation

x fix java compiler warnings

x fix valgrind errors and leaks (or extend suppressions)
    x libuv handles/allocations
    x btree_insert.cpp and others
    x txn_cursor.cpp
    x freelist reclaim
    x catch.hpp
    x fix TODO in PageManager::close
    x add remaining issues to suppressions (attn: there are two suppression
        files!)

x neues test-programm machen mit 15 simultaneous clients, selbe db
    x basierend auf client1.c
    x assert weil socket nicht geschlossen wurde
    x client hat "duplicate key" - warum?
    x server crasht mit assert, wenn eine db "close" macht und eine andere
        dann einen "find" -> benötigt reference counter? oder den close einfach
        nicht durchführen?
    x env_flush wird oft aufgerufen - warum??
    x use cursor-API instead of regular API
        -> fails w/ KEY_NOT_FOUND; seems to be a server-side issue?
    x frequently open/reopen the cursor
    x remove instrumentation in hamserver.cc
    x store the new test (in the unittests-directory?)
    x do NOT commit the modified client1.c file!
    x run tests on windows
    x the following messages do not need to send a full record in their
        request: DbFind(Record), CursorFind(Record), CursorMove(key, record)
        -> not true: need to transfer partial_offset, partial_size. But
            the record data is not required

o release-v2.pl enhancements
    x needs to run with enable-gcc-hardening tests
    x needs to run valgrind tests (check output - no leaks, no unsuppressed
        errors)
    x needs to run recovery tests
    x needs to run with static code analysis (clang)
    o new parameter "--start=3" in combination with "run": starts at
        step #3, executes all following steps
        "--stop=5": stops at step #5

o remote code crashes on win32
    o test the new sample in topic/remote on win32
    o send the new libraries to Phillip

o remote communication: should there be a configuration setting for
    client-side timeouts?

o server: what if there's a normal http request to the port? it should
    refuse the connection and wait for the next connection.
    just make sure this is no DOS attack.

o btree_erase.cc:72 - if coupled_index > 0 oder >= 0?
o btree_erase.cc:75 - wenn direkt remove_entry aufgerufen wird dann wird
    der gelöschte key nochmal uncouple()d obwohl das unnötig ist

o reimplement BtreeCursor::points_to (when extended keys are re-implemented)

x hamsterdb.cc should not call env->flush when creating or erasing a
    database. This should be called in LocalEnvironment! Otherwise
    the RemoteEnvironment also sends the request.

x run a test with the monster framework and check how much the disk space is
    reduced (pick one where the file size in bdb is very small)
    -> correct file size was not reported; fixed
    -> run monster tests and performance tests once more

. ham_env_open_db should no longer fail when opening a Database which
    was already opened. There should be an internal reference counter
    mechanism.
    o ham_env_close(HAM_AUTO_CLEANUP) forces the reference counter to 0
    o use this mechanism in hamserver (currently, it basically
        ignores ham_db_close)
>>>>>>> More fixes and a test program with multiple threads

. java-test fails on a slower machine (race cond. in finalize()?)
    -> this is just a test issue

. run a performance test clang++ vs g++
>>>>>>> Trying to track down Phillip's issue

------------------- release 2.1.2 -----------------------------------------




o rewrite configure.in; look at libuv for a good sample
        x also for bootstrap.sh
    x rename to configure.ac
    o also for monster tests
    o test on MacOS (tcmalloc must be disabled!)

o remove libjson, use boost::property_tree instead!

o btree_erase.cc:72 - if coupled_index > 0 oder >= 0?
o btree_erase.cc:75 - wenn direkt remove_entry aufgerufen wird dann wird
    der gelöschte key nochmal uncouple()d obwohl das unnötig ist

o reimplement BtreeCursor::points_to (when extended keys are re-implemented)

o remote communication: there should be a configuration setting for
    client-side timeouts

. review/rewrite/refactor Transaction class
    keep in mind that sooner or later the BtreeNode will expect template
    arguments; can we do something similar with the TransactionNode?
    x try to get the methods/design analoguous to the Btree - no, that
        does not make too much sense
    x document the tree structure in the header file
    x refactor the code
    o split into multiple files
    o try to cleanup the flow; move more code from db.cc to txn.cc
    . each Transaction should have its own PoolAllocator (based on ByteArray);
        when deleting the whole structure, only the PoolAllocator is freed
        o only do this if memory allocations cost performance
        o problem: a realloc() will not always work because it might move
            the allocated memory, and all existing pointers would be invalid 

o pre-allocate index; 1.10.x had this as an experimental feature
    o see roadmap document for more information
    o run a performance test/prototype if this is worth the effort
    o this feature is *per database*
    o calculate number of reqd pages based on estimated keys from the user
    o make sure that this is not reverted when "reduce file size" feature
        (above) is enabled
    o the new pages are not managed by the freelist! therefore the freelist
        will not need any modifications
    . try to batch allocations; when new pages are required then don't just
        allocate one but multiple pages

o collect file format incompatibilities
    o for the new Btree code (btree node, database header)
    o persistent freelist statistics
    o persistent freelist payload
    o page header - also store crc, page size
    o get rid of the statistics-structures
    o reduce the PBlobHeader (remove flags?, alloc_size)
    o for cache-oblivious (pre-allocated) index
    o what else?
    
    o increment file format counter and make sure that older database files
        can not be read by 2.1.3

o prepare btree rewrite; the goal is to move all node-specific operations
    into the node itself, and ultimately to get rid of BtreeIndex::compare

    o analyze node; move all node operations to the node itself
        o PBtreeNode::get_key()
        o find(key) -> position || kNotFound (== -1)
            -> BtreeIndex::get_slot
               (rename to get_position_in_page; returns position or kNotFound)
        o insert(key, RecordIdProxy) -> Proxy creates RecordId if insert is
                successful
            -> needs_split() -> bool
            -> split(Page *newpage, int pivot, bool internal)
            -> insert(key, record_proxy, flags = HINT_PREPEND, HINT_APPEND,
                        OVERWRITE, DUPLICATE) -> {slot, duplicate_id}
            -> append_no_split(key, record_proxy) -> {slot, duplicate_id}
            -> prepend_no_split(key, record_proxy) -> {slot, duplicate_id}
        o erase
            o remove_entry(Page, slot) -> erase_from_page(Page, slot)
            o copy_key(SrcPage, SrcSlot, DestPage, DestSlot)
            o replace_key(SrcPage, SrcSlot, DestPage, DestSlot)
            o shift
            o merge
        o what else?
            o Node::initialize() - called when a new page is allocated
            o need an "iterator" concept where it is possible to get the
              previous or the next key (for approx. matching and cursors)
            o need to change the PBtreeKey class - it might not have a size!
    o suggest new code flow
        o Abstract baseclass BtreeNodeProxy, which is then derived and
            implemented with template parameters. The generated pointer is
            stored in the Page object (make sure it's deleted when the page
            is moved to the freelist!). The BtreeNodeProxy will have all the
            additional logic for the PBtreeNode (which will not be modified).
        o Need a factory for BtreeNodeProxy objects
        o start by rewriting BtreeCheckIntegrityAction; use a template function
            to compare keys (which uses the pointer function internally)
            o add UINT32 keys (HAM_PARAM_KEY_TYPE == HAM_TYPE_UINT32) and
                implement a new Comparator
            o implement the BtreeNodeProxy class
                o needs get_position, get_key
            o implement the BtreeKeyProxy class
                o for variable size (existing) keys
                o for fixed size keys (uint32, uint64...)
        o then rewrite BtreeEnumAction

o start with the Btree rewrite; btree nodes are accepting template parameters
    and policies. The default parameter uses the callback function provided
    by the user. There are many notes on paper flying around - collect
    and consolidate them first.
    o support existing callbacks - everything should work as advertised
    o support binary search and linear search through a node
    o support POD types: int8, uint8, int16, uint16, int32, uint32, int64,
        uint64, float, double, fixed length blobs, fixed length strings (?)
        (w/o duplicates and extended keys - they always enforce the
        default type based on the callback)
    ------- release -------
    o support variable length types, use linear search (with a skiplist)
        for strings (strcmp), blobs (memcmp)
    o replace extended keys; store them in the leaf unless they're TOO big
        (then either use an overflow area or refuse to store them i.e. if
        they are > 20% of the page - better refuse, then we can also get
        rid of the error code that can be returned by the compare function)
        -- really? wouldn't this be inconvenient for the users?
    ------- release -------
    o replace duplicate keys; this will be difficult because it requires
        rewriting the Cursor consolidation flow
    ------- release -------
    o optionally store fixed length record in leaf (not in internal pages!)
    ------- release -------
    o add column store compression for keys, lightweight compression for
        records (snappy, etc)
    ------- release -------
    o add "functions" and predicate scans, i.e. COUNT() w/ predicates???










. BtreeCursor: use memory arena for uncoupling the key
    -> better wait till extended keys are gone

. java-test fails on a slower machine (race cond. in finalize()?)
    -> this is just a test issue; the finalizer does not close the database
    objects soon enough, and the db-file is still locked when the next
    test starts. Could be fixed by using temporary file names for the tests.

. also remove locking from C# and Java APIs

o is the recovery working if there's a crash during ham_db_close
    or ham_env_close?





------------------- idea soup ---------------------------------------------

o allow transactions w/o journal

o allow transactions w/o recovery

o when recovering, give users the choice if active transactions should be
    aborted (default behavior) or re-created
    o needs a function to enumerate them

o when flushing the Changeset: batch ALL changes for the WHOLE transaction,
    then flush all of them together. This way we can "merge" multiple changes
    for the same page.
    Also review the whole flush process - when not to log etc.
    - only 1 page affected: no need to log it because it is idempotent
    - freelist pages are always idempotent
    - more than 1 index page? not idempotent (most likely)
    - more than 1 blob page? not idempotent (maybe)
    o define a few benchmarks
    o be careful: if N operations are modifying the same changelog, and
        then #N+1 aborts then the aborting operation must NOT clear the
        changelog!

o A new transactional mode: read-only transactions can run "in the past" - only
    on committed transactions. therefore they avoid conflicts and will always
    succeed.

o changeset: instead of simply adding pages to the changeset, the caller
    could already specify whether this page needs logging or not;
    i.e. after freelist rewrite, the blob pages do not need logging if a
    blob is deleted  

o is there a way to group all changeset flushes of a Transaction into one
    changeset, and batch-commit multiple commits? that way we would avoid the
    frequent syncs and performance would be improved
    o would have to remove all of assert(changeset.is_empty())
    o but we can use that assert prior to txn_begin

o BtreeFindAction: always use a cursor, and when doing approx matching
    then simply move left or right with that cursor

. track additional metrics
    o cache misses
    o cache hits
    o ...

o flush in background (asynchronously)
    o need new flag file HAM_DISABLE_ASYNCHRONOUS_FLUSH
    o if in-memory database: disable async flush
    o if transactions are disabled: disable async flush
    o if enabled: create background thread, wait for signal
    o ham_env_flush: if txn are enabled then try to flush them to disk
    o how to deal with an error in the background thread???
        o store in Environment, then return in every exported function
    o default: async flush is OFF!

    o extend monster tests
        o with async flush
        o without async flush
        o extend/run performance test
        o run monster tests

    o documentation
        o tutorial
        o faq

o need a function to get the txn of a conflict (same as in v2)
    ham_status_t ham_txn_get_conflicting_txn(ham_txn_t *txn, ham_txn_t **other);
        oder: txn-id zurückgeben? sonst gibt's ne race condition wenn ein anderer
        thread "other" committed/aborted
    o also add to c++ API
    o add documentation (header file)
    o add documentation (wiki)

. new test case for cursors
    insert (1, a)
    insert (1, b) (duplicate of 1)
    move (last) (-> 1, b)
    insert (1, c)
    move (last) (-> 1, c)? is the dupecache updated correctly?

. there are a couple of areas where a btree cursor is uncoupled, just to
    retrieve the key and to couple the txn-key. that's not efficient
        db.c:__btree_cursor_points_to
        db.c:__compare_cursors
        txn_cursor.c:cursor_sync
        txn_cursor.c:cursor_overwrite
    o move to a separate function
    o try to optimize

. add tests to verify that the cursor is not modified if an operation fails!
    (in cursor.cpp:LongTxnCursorTest are some wrapper functions to move or
    insert the cursor; that's a good starting point)

. new flag for transactions: HAM_TXN_WILL_COMMIT
    if this flag is set, then write all records directly to the file, not
    to the log. the log will only contain the rid.
    -> or: make this the default; call the new flag HAM_TXN_MAYBE_WILL_ABORT
    o in case of an abort: move the record to the freelist
    -> this affects all temporary ham_insert-transactions
    (not sure if this should get high priority)

. if memory consumption in the txn-tree is too high: flush records to disk
    (not sure if this should get high priority)

o ham_get_count: could be atomically updated with every journal entry

